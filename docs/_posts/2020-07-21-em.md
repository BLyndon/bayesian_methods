---
layout: page
title: "2.1 General Expectation Maximation Algorithm"
permalink: /bayesian_methods/em/
---
* ToC
{:toc}
During the training of a model, the parameter $$\theta$$ is tuned to maximize the likelihood $$p(X\|\theta)$$ of the observed dataset.

For i.i.d. data points the loglikelihood factorizes. Using the chain rule, we introduce a latent variables $$t_i$$

$$
    \log p(X|\theta) = \sum_i log p(x_i|\theta) = \sum_{i} \log \sum_{c}p(x_i, t_i=c| \theta)
$$

The advantage of the EM algorithm is to maximize a lower bound instead of the complicated loglikelihood $$p(X\|\theta)$$. To find a lower bound we make use of the [Jenson inequality](https://en.wikipedia.org/wiki/Jensen%27s_inequality). But first, we need to transform the argument of the logarithm by inserting $$1 = \frac{q(t_i=c)}{q(t_i=c)}$$

$$
    \log p(X|\theta) = \sum_{i} \log \sum_{c}q(t_i=c) \frac{p(x_i, t_i=c| \theta)}{q(t_i=c)} = \sum_i \log \left \langle \frac{p(X,t_i|\theta)}{q(t_i)} \right\rangle_{q(t)}
$$

By this trick, Jenson inequality is applicable and we find a lower bound $$\mathcal L(\theta, q)$$

$$
    \log p(X|\theta) = \sum_i \log \left \langle \frac{p(X,t_i|\theta)}{q(t_i)} \right\rangle_{q(t)} \geq \sum_i \left \langle \log \left( \frac{p(X,t_i|\theta)}{q(t_i)}\right) \right \rangle_{q(t)}
$$

## The EM-algorithm

The lower bound $$\mathcal L (\theta, q)$$ now, is maximized in two steps. In the first step, called the **expectation step**,  we vary $$q(t_i)$$ while $$\theta$$ is kept fix. 

It can be shown, that the gap $$\Delta$$ between the loglikelihood $$p(X\|\theta)$$ and the lower bound $$\mathcal L$$ is given by the Kullback-Leibler divergence

$$
    \Delta = \log p(X|\theta) - \mathcal L(\theta, q) = \mathcal{KL}\left(q(t_i) || p(t_i| x_i, \theta)\right)
$$

which is minimized by $$q(t_i) = p(t_i\| x_i, \theta)$$.

In the second step, called the **maximization step**, the parameter $$\theta$$ is tuned to maximize the lower bound for the particular choice of $$q$$

$$
    \mathcal L(\theta, q) = \sum_i \langle \log \left(p(X,t_i|\theta)\right)\rangle_{q(t_i)} + const.
$$

The second term is constant w.r.t. $$\theta$$, the first term is usually concave and thus easily maximized by gradient ascent.

## Update Formulas

**E-step:**

$$
    q^{k+1}(t_i) = p(t_i| x_i, \theta^k) = \frac{p(x_i|t_i, \theta^k) q^k(t_i)}{\sum_c p(x_i|t_i=c, \theta^k) q^k(t_i=c)}
$$

**M-step:**

$$
    \theta^{k+1} = \text{argmax} \sum_i \mathbb E_{q^{k+1}(t_i)} \log \left(p(x_i,t_i|\theta^k)\right)
$$

